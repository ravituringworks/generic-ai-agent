{
  "name": "Basic Text Generation",
  "description": "Simple workflow demonstrating text input, LLM generation, and text output",
  "nodes": [
    {
      "id": "input_1",
      "node_type": "text_input",
      "position": {
        "x": 50,
        "y": 150
      },
      "config": {
        "text": "Write a haiku about programming"
      },
      "label": "Prompt Input"
    },
    {
      "id": "model_1",
      "node_type": "model_config",
      "position": {
        "x": 50,
        "y": 280
      },
      "config": {
        "provider": "ollama",
        "model": "qwen3-coder:480b-cloud",
        "base_url": "http://localhost:11434",
        "temperature": 0.7,
        "max_tokens": 2048,
        "api_key": "",
        "api_version": "2024-02-15-preview",
        "deployment_name": "",
        "embedding_model": "",
        "provider_options": {},
        "stream": false,
        "system_prompt": "",
        "timeout": 60,
        "top_p": 0.9
      },
      "label": "Ollama Config"
    },
    {
      "id": "llm_1",
      "node_type": "llm_generate",
      "position": {
        "x": 350,
        "y": 180
      },
      "config": {
        "temperature": 0.7,
        "max_tokens": 1000
      },
      "label": "Generate Haiku"
    },
    {
      "id": "output_1",
      "node_type": "text_output",
      "position": {
        "x": 650,
        "y": 190
      },
      "config": {
        "label": "Generated Haiku",
        "format": "plain"
      },
      "label": "Display Result"
    }
  ],
  "connections": [
    {
      "id": "conn_1",
      "from_node": "input_1",
      "from_output": "text",
      "to_node": "llm_1",
      "to_input": "prompt"
    },
    {
      "id": "conn_2",
      "from_node": "model_1",
      "from_output": "config",
      "to_node": "llm_1",
      "to_input": "model_config"
    },
    {
      "id": "conn_3",
      "from_node": "llm_1",
      "from_output": "response",
      "to_node": "output_1",
      "to_input": "text"
    }
  ],
  "exported_at": "2025-01-08T00:00:00.000Z",
  "version": "1.0",
  "workflow_id": "00000000-0000-0000-0000-000000000001"
}